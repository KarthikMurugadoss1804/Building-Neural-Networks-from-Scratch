{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "from keras.utils import np_utils\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training features  (60000, 784)\n",
      "Shape of test features  (10000, 784)\n",
      "Shape of training labels  (10, 60000)\n",
      "Shape of testing labels  (10, 10000)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
    "\n",
    "# load the training and test data    \n",
    "(tr_x, tr_y), (te_x, te_y) = fashion_mnist.load_data()\n",
    "\n",
    "# reshape the feature data\n",
    "tr_x = tr_x.reshape(tr_x.shape[0], 784)\n",
    "te_x = te_x.reshape(te_x.shape[0], 784)\n",
    "\n",
    "# noramlise feature data\n",
    "tr_x = tr_x / 255.0\n",
    "te_x = te_x / 255.0\n",
    "\n",
    "print( \"Shape of training features \", tr_x.shape)\n",
    "print( \"Shape of test features \", te_x.shape)\n",
    "\n",
    "\n",
    "# one hot encode the training labels and get the transpose\n",
    "tr_y = np_utils.to_categorical(tr_y,10)\n",
    "tr_y = tr_y.T\n",
    "print (\"Shape of training labels \", tr_y.shape)\n",
    "\n",
    "# one hot encode the test labels and get the transpose\n",
    "te_y = np_utils.to_categorical(te_y,10)\n",
    "te_y = te_y.T\n",
    "print (\"Shape of testing labels \", te_y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training features  (784, 60000)\n",
      "Shape of test features  (784, 10000)\n"
     ]
    }
   ],
   "source": [
    "#Reshaping Training data to n x m matrix \n",
    "tr_x_reshaped = tr_x.T \n",
    "#Reshaping test data to n x m matrix \n",
    "te_x_reshaped = te_x.T\n",
    "print( \"Shape of training features \", tr_x_reshaped.shape)\n",
    "print( \"Shape of test features \", te_x_reshaped.shape)\n",
    "tr_y = tf.constant(tr_y)\n",
    "te_y = tf.constant(te_y)\n",
    "tr_x_reshaped = tf.constant(tr_x_reshaped)\n",
    "te_x_reshaped = tf.constant(te_x_reshaped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Weights  (10, 784)\n",
      "Shape of bias  (10, 1)\n"
     ]
    }
   ],
   "source": [
    "W = tf.Variable(tf.random.normal([ 10,tr_x_reshaped.shape[0]], mean=0.0, stddev=0.05))\n",
    "b = tf.Variable(tf.zeros(shape = (10,1)))\n",
    "\n",
    "print(\"Shape of Weights \", W.shape)\n",
    "\n",
    "print(\"Shape of bias \", b.shape)\n",
    "\n",
    "\n",
    "\n",
    "def forward_pass(X,W,b):\n",
    "    WX = tf.matmul(tf.cast(W, tf.float32),tf.cast(X, tf.float32))\n",
    "    A1 = tf.add(WX,b)\n",
    "    H = softmax(A1)\n",
    "    H = tf.clip_by_value(H, 1e-10, 1.0)\n",
    "    return H\n",
    "\n",
    "def cross_entropy(H,y):\n",
    "    loss  = -tf.reduce_sum(tf.math.multiply(y, tf.math.log(H)),0)\n",
    "    total_loss = tf.reduce_mean(loss)\n",
    "    return total_loss\n",
    "    \n",
    "    \n",
    "def calculate_accuracy(x,y,w,b):\n",
    "    y_pred_softmax = forward_pass(x, w, b)\n",
    "    predictions = tf.math.argmax(y_pred_softmax)\n",
    "    actual_y = tf.math.argmax(y)\n",
    "    predictions_correct = tf.cast(tf.equal(predictions, actual_y), tf.float32)\n",
    "    accuracy = tf.reduce_mean(predictions_correct)\n",
    "    return accuracy\n",
    "\n",
    "def softmax(A):\n",
    "    t = tf.math.exp(A)\n",
    "    sum_of_t = tf.reduce_sum(t, 0)\n",
    "    soft_max_output = tf.math.divide(t, sum_of_t)\n",
    "    return soft_max_output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_Iterations = 11000\n",
    "adam_optimizer = tf.keras.optimizers.Adam()\n",
    "trainingLoss= []\n",
    "validationLoss= []\n",
    "trainingAccuracies = []\n",
    "validationAccuracies = []\n",
    "\n",
    "for i in range(num_Iterations):\n",
    "    with tf.GradientTape() as tape:\n",
    "        y_pred = forward_pass(tr_x_reshaped, W, b)\n",
    "        currentLoss = cross_entropy(y_pred,tr_y)\n",
    "        gradients = tape.gradient(currentLoss, [W, b])\n",
    "    accuracy = calculate_accuracy(tr_x_reshaped, tr_y, W, b)\n",
    "    trainingLoss.append(currentLoss)\n",
    "    trainingAccuracies.append(accuracy)\n",
    "    y_pred_test = forward_pass(te_x_reshaped, W, b)\n",
    "    currentLoss_test = cross_entropy(y_pred_test,te_y)\n",
    "    accuracy_test = calculate_accuracy(te_x_reshaped, te_y, W, b)\n",
    "    validationLoss.append(currentLoss_test)\n",
    "    validationAccuracies.append(accuracy_test)\n",
    "    #print (\"Iteration \", i, \": Loss = \",currentLoss.numpy(), \"  Acc: \", accuracy.numpy())\n",
    "    #print (\"\")\n",
    "    adam_optimizer.apply_gradients(zip(gradients, [W,b]))\n",
    "print(\"Final Accuracy: \", accuracy.numpy() , \"Final Loss: \", currentLoss.numpy())\n",
    "print(\"Final Test Accuracy: \", accuracy_test.numpy() , \"Final Test Loss: \", currentLoss_test.numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(validationLoss, label=\"Val Loss\")\n",
    "plt.plot(validationAccuracies, label=\"Val Acc\")\n",
    "\n",
    "plt.plot(trainingLoss, label=\"Train Loss\")\n",
    "plt.plot(trainingAccuracies, label=\"Train Acc\")\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
